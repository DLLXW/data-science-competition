## [华为云“云上先锋”· AI挑战赛--街景图像分割](https://competition.huaweicloud.com/information/1000041336/introduction)

经过了一个月的角逐,我最终在该比赛上面取得了**亚军**，这里分享一下自己的解决思路
### 问题描述
该比赛的数据集同cityscape的数据集极其相似，唯一不同的地方在于该比赛需要将街景图像分成7个类别（对应了cityscape的7个大类）,可以理解为对cityscape数据集进行一个粗粒度的语义分割。因为cityscape原本是针对19类更细粒度的语义分割任务。
### 数据集转化
其实这一步可以说是劝退了很多的小白,以及没有耐心去仔细阅读cityscape官方文档的选手，很多人连训练数据都没法正确的处理好。这也是为什么排行榜上面那么多低分的原因。官方提供了2k+的标注数据,不过其格式为.json，也就是将标注的结果放在json文件里面,选手如果需要自行训练模型,有两种选择:

1.自己写一个针对该格式的dataloader(这种方式也不是不行,但是过于复杂)。

2.将json里面的标注信息画在一张灰度图上面(背景用255来表征),7个类别就是对应了0-6个灰度值。这其实也是大多数语义分割任务的标准格式。

下面讲一下如何将json里面的信息画在灰度图上面，我一开始是自己写的,后面发现有一个现成的cityscapesscripts开源工具库开源使用,但是如果对cityscape的数据详情不了解,是很难对其进行合理的应用到此次的数据上来的。

json_to_png.py：将原始的json标注转换为灰度图,背景类别用255表示,0-6分别代表官方指定的7个类别。这里说一下背景类:其实cityscape里面是没有背景类的,只是有一个忽略类别,但通过观察原始数据发现,很多图片里面都有未标注的区域，所以这里也就是使用255来表示忽略类。

make_city_scape.py: 制作cityscape训练数据,官方明确说明了可以使用cityscape训练数据,但问题在于原本的cityscape标注是19类的细粒度标注，我们该如何将其转为7个类别的粗粒度标注?这里还是得利用cityscapesscripts开源工具箱,道理其实同上面的json_to_png一样,只需要我们在转的时候指定好类别即可。

###  模型和训练trick

经过各种尝试,最终选定了OCRNet,基于open-mmlab开源的mmsegmentation

- backbone:HRNetV2p-w48
- loss:交叉熵
- 先将图像resize到二倍大小,然后使用随机crop的方式进行裁剪送入模型训练,可以配合使用水平flip，除此之外无额外的数据增强
- OHEM
- fp16(算力不够),fp32(算力充足),因为是cpu推理,所以推理速度方面二者并无太大差距。

单独的官方数据和加上cityscape的训练数据相比,最终线上效果并未太大的差别,猜测可能官方数据的标注风格和cityscape或多或少有一些差别,加入了更多的数据也引入了更大的差异。

### 总结

此次比赛其实如果找到了一个合适的模型,再加上充足的算力,基本可以很容易进入排行榜的top。deeplabv3-plus也能获得87.5+的线上分数,因为推理时间的限制很多其余模型和backbone也并未做更多的尝试!总而言之,这其实是一场算力大赛,没有48g+的显存,基本不可能取得一个较好的名次。