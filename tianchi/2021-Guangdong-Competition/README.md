## [2021广东工业智造创新大赛—智能算法赛](https://tianchi.aliyun.com/competition/entrance/531846/introduction)

## 2021.1.15更新 baseline基于yolov5

由于手头只有RTX 2070s，虽然大家都在卷mmdetection,但我这8g算力实在搞不过,配置文件给我我都训不出来，本来这比赛都没打算再做了，那天开源了转换/切图思路后本repo star涨了很多，瑟瑟发抖，正好手头有yolov5的代码和各种转换脚本，所以花了半天时间做一个baseline，而且考虑到速度和精度的均衡（复赛要求<3s）,如果使用two-stage的单图大尺度预测，个人感觉上限有限,而且比赛最后都是拼细节。所以肯定会朝着切图(特别是测试时切图)的方向发展。如果two-stage妄图切图到小块然后预测，3s肯定顶不住，所以选择yolov5作为基线供大家参考！欢迎交流~~

**关于预训练模型**: 这个版本的yolov5是去年六七月份的，现在的[最新版ultralytics/yolov5](https://github.com/ultralytics/yolov5)里面能下载到的预训练模型无法直接用在这套旧版本代码上。所以建议大家都clone目前官方git仓库的最新代码和最新权重。如果非要使用这套yolov5代码，也可以到我的网盘下载[yolov5预训练密码:1234](https://pan.baidu.com/s/1C_C65eAL5T-6wYd5gkbG6w)，下载好了放到yolov5/weights下即可。

**关于环境**:本套代码需要torch>1.4

**切图**：

- 先将图片离线切成640x640, 剔除纯背景,大约会生成1.9w+的训练图像
- 预测的时候也是将图片切成640x640.这样一张图片大约会变成150~200张小图,而yolov5l的FPS在v100上大约为256. 所以可以保证在3s内可以完成一张图的预测。

**训练**：

- 训练尺度:640x640 ; 30 epoch ; 0.1比例验证(训练未见过的图片的切片) ,严格的验证还需要算上切出来的背景块。
- 线下:mAP@0.5: 60
- 2卡2070s训练，训练时间<6hour。

**测试:**
1.16更新，设置大overlap加上经过NMS后处理，切图预测的表现大幅提升，比原图预测高一个点。
​	单卡:RTX 2070s

- 切成 640x640 滑动窗口预测，耗时<1.5 h, 平均一张图<3s!.线上50.（低于原图预测的结果我是没想到的,没有NMS后处理？或者代码写错了?或者滑窗就是不行?）

- 长边resize到6400预测,平均一张图耗时:0.6 s. 线上55+

代码运行说明:

python

```bash
python convert_to_voc.py #先将原始数据转为VOC格式的标注
python make_slice_voc.py #将上述图片切为小图，重新制作为voc.
python convert_voc_to_v5txt.py #将voc标注转换为yolov5的官方格式.
python make_yolov5_train_val.py #制作yolov5的train/val.
```
- yolov5/train.py #训练参数设置
- yolov5/infer_tile.py #单图大尺度预测
- yolov5/infer_slice_tile.py #切图滑窗预测

**关于跑make_slice_voc.py却没有"./yolov5/voc/JPEGImages"的错误,这里的JPEGImage就是原始图像，建议把原始图像复制到voc下，重命名为JPEGImages,或者建立一个软连接。**

总结:
其实训练切图和预测，特别是预测部分，整个baseline做到还很粗糙。yolov5的速度保证下，在这个比赛后期想必是极具竞争力的。

关于切图滑窗预测: 如果处理好细节，切图预测理论上应该是会好于原图预测。但针对那些背景块，需要特殊处理，不然会引入极多的FP,必然导致mAP降低。关于overlap的问题，这里开源借鉴模型融合的方式，使用WBF来对最后的重叠进行一个再处理。

关于单图预测：考虑推理速度尺度,中心裁剪推理,其实所有图都有灰边背景，统计下这些背景的边框范围,进行centerCrop预测结果应该会更好，不想麻烦的化直接在推理结果上面进行后处理也行。


## 附： 切图操作思路分享
鉴于很多朋友在讨论如何切图，存在的主要问题是训练的时候切图需要考虑标签的几何变化,测试时候切图需要考虑如何拼接起来，经过一下午的研究，实现了整个流程。这里开源下解决思路：

#### 参考卫星图像目标检测处理方法。

假设:

- 待切的原图大小为:h=6000,w=8192.
<<<<<<< HEAD
- overlop比例:0.2，切图尺寸:640x640
=======
- 需要切图的大小为:640x640,overlop比例:0.2
>>>>>>> ff07fbda95ad0570537cd964bc8bc2925ce5b2f3
- 则步长为512.
- 从原图左上角开始切图,切出来图像的左上角记为x,y,
- 那么可以容易想到y依次为:0,512,1024,....,5120.但接下来却并非是5632,因为5632+640>6000,所以这里要对切图的overlop做一个调整,最后一步的y=6000-640.(这是最关键的一点！！！)

<img src="slice/5.png" alt="切出缺陷位置" style="zoom:33%;" />

#### 关于标签的变化

根据上面的切图思路,目标的标签:x_min,y_min,x_max,y_max要分配给每一个被切出来的小图(640x640)，剩下的图当做背景过滤掉。

假设:

- 当前"小图"的左上角坐标在原图中的位置为:s_x_min,s_y_min.
- 原图上面有一个框的坐标为:x_min,y_min,x_max,y_max.
- 如果该框在该"小图"内部(这个根据坐标很好判断),
  - 则该框相对于该"小图"的新坐标:x_min-s_x_min,y_min-s_y_min

以上便为全过程。



<img src="slice/3.jpg" alt="几何关系" style="zoom:50%;" />

**可视化证明标签变化正确:**

<img src="slice/6.png" style="zoom:50%;" />

#### 关于推理

推理部分没有标签的变化,主要需要考虑的是将切好的图进行预测后再拼起来,这个操作实质上是上面的逆向操作。反过来就行，完事之后再来一个整体的NMS即可!


关于代码:等后面把整个baseline做好了再开源吧,ps：如果有算力的大佬愿意合作的请加我github主页微信
